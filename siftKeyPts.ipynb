{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcqq58IqkZuL0seQIj/aVn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oepyGqtNH9ZA","executionInfo":{"status":"ok","timestamp":1696996044320,"user_tz":300,"elapsed":15619,"user":{"displayName":"nikita pawale","userId":"05169722051449775187"}},"outputId":"3b5425df-3da0-4ec5-95ee-94c35dfeffa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import cv2\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.models import load_model\n","from keras.preprocessing.image import img_to_array\n","\n","best_score=0\n","filename=None\n","image =None\n","kp1,kp2, mp= None, None, None\n","for file in [file for file in os.listdir(\"/content/drive/MyDrive/SOCOFing/SOCOFing/Real\")[:1]]:\n","        print(file)\n","        filepath =\"/content/drive/MyDrive/SOCOFing/SOCOFing/Real/100__M_Left_index_finger.BMP\"\n","        filepath_sample =\"/content/drive/MyDrive/SOCOFing/SOCOFing/Altered/Altered-Easy/\"+file.split(\".\")[0]+'_CR.BMP'\n","        sample_1=cv2.imread(filepath)\n","        sample=cv2.imread(filepath_sample)\n","        print(filepath)\n","        sift = cv2.SIFT_create()\n","        keypoint1, descriptor1 = sift.detectAndCompute(sample_1, None)\n","        keypoint2, descriptor2 = sift.detectAndCompute(sample, None)\n","\n","        # FLANN parameters\n","        flann_params = {\n","            'algorithm': 1,  # FLANN_INDEX_KDTREE\n","            'trees': 10\n","        }\n","\n","        # Create FLANN matcher\n","        flann = cv2.FlannBasedMatcher(flann_params, {})\n","        # Perform KNN matching\n","        matches = flann.knnMatch(descriptor1, descriptor2, k=2)\n","\n","                # Filter good matches\n","        good_matches = []\n","        for m, n in matches:\n","            if m.distance < 0.7 * n.distance:\n","                good_matches.append(m)\n","\n","        # Draw the matches\n","        result_image = cv2.drawMatches(sample_1, keypoint1, sample, keypoint2, good_matches, None)\n","        print(\"good_matches\",len(good_matches))\n","\n","        # Show the result\n","        cv2_imshow(result_image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"-CRZBstmIGMh","executionInfo":{"status":"error","timestamp":1696996241340,"user_tz":300,"elapsed":5180,"user":{"displayName":"nikita pawale","userId":"05169722051449775187"}},"outputId":"030751c0-81e2-4804-8ffb-a206cda66cbe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["551__F_Right_index_finger.BMP\n","/content/drive/MyDrive/SOCOFing/SOCOFing/Real/100__M_Left_index_finger.BMP\n","good_matches 0\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b563637d5469>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Show the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cv2_imshow' is not defined"]}]},{"cell_type":"code","source":["def pixel_mse_loss(x,y):\n","    return tf.reduce_mean( (x - y) ** 2 )\n","\n","\n","def PSNR(y_true,y_pred):\n","    mse=tf.reduce_mean( (y_true - y_pred) ** 2 )\n","    return 20 * log10(1/ (mse ** 0.5))\n","\n","def log10(x):\n","    numerator = tf.math.log(x)\n","    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n","    return numerator / denominator\n","\n","def pixel_MSE(y_true,y_pred):\n","    return tf.reduce_mean( (y_true - y_pred) ** 2 )"],"metadata":{"id":"-Q0ld8ddAC4j","executionInfo":{"status":"ok","timestamp":1696996300695,"user_tz":300,"elapsed":2,"user":{"displayName":"nikita pawale","userId":"05169722051449775187"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def contrastive_loss_with_margin(margin):\n","  def contrastive_loss(y_true, y_pred):\n","    square_pred = K.square(y_pred)\n","    margin_square = K.square(K.maximum(margin - y_pred, 0))\n","    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n","  return contrastive_loss"],"metadata":{"id":"9yQOuY6CAFkS","executionInfo":{"status":"ok","timestamp":1696996302303,"user_tz":300,"elapsed":109,"user":{"displayName":"nikita pawale","userId":"05169722051449775187"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.models import load_model\n","from keras.preprocessing.image import img_to_array\n","\n","# Load the SRCNN model\n","model = load_model('/content/drive/MyDrive/Model/srcnn_model_soco_15k.h5', custom_objects={'pixel_mse_loss': pixel_mse_loss, 'PSNR': PSNR})\n","\n","\n","best_score=0\n","filename=None\n","image =None\n","kp1,kp2, mp= None, None, None\n","for file in [file for file in os.listdir(\"/content/drive/MyDrive/SOCOFing/SOCOFing/Real\")[:10]]:\n","        print(file)\n","        filepath =\"/content/drive/MyDrive/SOCOFing/SOCOFing/Real/100__M_Left_thumb_finger.BMP\"\n","        filepath_sample =\"/content/drive/MyDrive/SOCOFing/SOCOFing/Altered/Altered-Easy/\"+file.split(\".\")[0]+'_Zcut.BMP'\n","        sample_1=cv2.imread(filepath)\n","        sample=cv2.imread(filepath_sample)\n","        print(filepath)\n","        sift = cv2.SIFT_create()\n","        keypoint1, descriptor1 = sift.detectAndCompute(sample_1, None)\n","        keypoint2, descriptor2 = sift.detectAndCompute(sample, None)\n","\n","        # FLANN parameters\n","        flann_params = {\n","            'algorithm': 1,  # FLANN_INDEX_KDTREE\n","            'trees': 10\n","        }\n","\n","        # Create FLANN matcher\n","        flann = cv2.FlannBasedMatcher(flann_params, {})\n","        # Perform KNN matching\n","        matches = flann.knnMatch(descriptor1, descriptor2, k=2)\n","\n","                # Filter good matches\n","        good_matches = []\n","        for m, n in matches:\n","            if m.distance < 0.7 * n.distance:\n","                good_matches.append(m)\n","\n","        # Draw the matches\n","        result_image = cv2.drawMatches(sample_1, keypoint1, sample, keypoint2, good_matches, None)\n","        print(\"good_matches\",len(good_matches))\n","\n","        # Show the result\n","        cv2_imshow(result_image)\n","\n","                # Load and preprocess the input image\n","        #input_image_path = '/content/drive/MyDrive/SOCOFing/SOCOFing/Altered/Altered-Hard/100__M_Left_index_finger_Obl.BMP'  # Replace with the path to your input image\n","        input_image = cv2.imread(filepath)\n","        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n","        input_image = cv2.resize(input_image, (256, 256))\n","        input_image = input_image.astype('float32') / 255.0\n","\n","        # Predict the high-resolution image\n","        input_array = np.expand_dims(input_image, axis=0)\n","\n","        predicted_image1 = model.predict(input_array)[0]\n","\n","\n","\n","        input_image1 = cv2.imread(filepath_sample)\n","        input_image1 = cv2.cvtColor(input_image1, cv2.COLOR_BGR2RGB)\n","        input_image1 = cv2.resize(input_image1, (256, 256))\n","        input_image1 = input_image1.astype('float32') / 255.0\n","\n","        # Predict the high-resolution image\n","        input_array1 = np.expand_dims(input_image1, axis=0)\n","\n","        predicted_image2 = model.predict(input_array1)[0]\n","                # Display the input and predicted images\n","        plt.figure(figsize=(12, 6))\n","        plt.subplot(1, 2, 1)\n","        plt.title('Predicted Image1')\n","        plt.imshow(predicted_image1)\n","        plt.axis('off')\n","\n","        plt.subplot(1, 2, 2)\n","        plt.title('Predicted Image2')\n","        plt.imshow(predicted_image2)\n","        plt.axis('off')\n","\n","        plt.show()\n","        # Save the predicted image as a file\n","        output_path1 = '/content/sample_data/predicted_image1.BMP'\n","        cv2.imwrite(output_path1, cv2.cvtColor(predicted_image1 * 255, cv2.COLOR_RGB2BGR))\n","        output_path1 = '/content/sample_data/predicted_image2.BMP'\n","        cv2.imwrite(output_path1, cv2.cvtColor(predicted_image2 * 255, cv2.COLOR_RGB2BGR))\n","\n","        filepath =\"/content/sample_data/predicted_image1.BMP\"\n","        filepath_sample =\"/content/sample_data/predicted_image2.BMP\"\n","        sample_1=cv2.imread(filepath)\n","        sample=cv2.imread(filepath_sample)\n","        sift = cv2.SIFT_create()\n","        keypoint1, descriptor1 = sift.detectAndCompute(sample_1, None)\n","        keypoint2, descriptor2 = sift.detectAndCompute(sample, None)\n","\n","        # FLANN parameters\n","        flann_params = {\n","            'algorithm': 1,  # FLANN_INDEX_KDTREE\n","            'trees': 10\n","        }\n","\n","        # Create FLANN matcher\n","        flann = cv2.FlannBasedMatcher(flann_params, {})\n","        # Perform KNN matching\n","        matches = flann.knnMatch(descriptor1, descriptor2, k=2)\n","\n","                # Filter good matches\n","        good_matches = []\n","        for m, n in matches:\n","            if m.distance < 0.7 * n.distance:\n","                good_matches.append(m)\n","\n","        # Draw the matches\n","        result_image = cv2.drawMatches(sample_1, keypoint1, sample, keypoint2, good_matches, None)\n","        print(\"good_matches\",len(good_matches))\n","\n","        # Show the result\n","        cv2_imshow(result_image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1IAhhasHoDg7-v8VtYUmyA0t_v88oUems"},"id":"MWCMu1EJ-Pen","executionInfo":{"status":"ok","timestamp":1696996476491,"user_tz":300,"elapsed":13616,"user":{"displayName":"nikita pawale","userId":"05169722051449775187"}},"outputId":"9cb1cc5e-c3c4-4fd9-95af-c1eaaed6a11f"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["!pip3 install opencv-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fP5Q_6j8Orb1","executionInfo":{"status":"ok","timestamp":1696801183782,"user_tz":300,"elapsed":5029,"user":{"displayName":"nikita pawale","userId":"05169722051449775187"}},"outputId":"bdd876af-f769-4d94-ca45-e71543adba6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"]}]}]}